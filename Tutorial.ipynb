{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tutorial**:\n",
    " \n",
    "1. Download project and install dependencies\n",
    "2. Preprocess data\n",
    "3. Segment preprocessed data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Download the BrainLes Aurora package**\n",
    "\n",
    "Download the github project with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install brainles_aurora"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install a preprocessing package, e.g. BraTS-Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install BraTS-Toolkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the instructione on the Github-page for installation and setup advice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Segment preprocessed data**\n",
    "\n",
    "We provide sample data from the [ASNR-MICCAI BraTS Brain Metastasis Challenge](https://www.synapse.org/#!Synapse:syn51156910/wiki/622553), which is already preprocessed.\n",
    "\n",
    "Minimal mode: Segmentation without test-time augmentation with only T1-CE as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Minimal example__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 20:13:13 INFO: Initialized AuroraGPUInferer with config: AuroraInfererConfig(output_mode=<DataMode.NIFTI_FILE: 'NIFTI_FILEPATH'>, log_level=20, tta=False, sliding_window_batch_size=1, workers=0, threshold=0.5, sliding_window_overlap=0.5, crop_size=(192, 192, 32), model_selection=<ModelSelection.BEST: 'best'>, include_whole_network_in_numpy_output_mode=False, include_metastasis_network_in_numpy_output_mode=False)\n",
      "2024-01-16 20:13:13 INFO: Using device: cuda\n",
      "2024-01-16 20:13:13 INFO: Logging to: test_output/segmentation.nii.log\n",
      "2024-01-16 20:13:13 INFO: Running inference on cuda\n",
      "2024-01-16 20:13:13 INFO: Successfully validated input images. Input mode: NIFTI_FILEPATH\n",
      "2024-01-16 20:13:13 INFO: Received files: T1: True, T1C: False, T2: False, FLAIR: False\n",
      "2024-01-16 20:13:13 INFO: Inference mode: t1-o\n",
      "2024-01-16 20:13:13 INFO: No loaded compatible model found. Loading Model and weights\n",
      "2024-01-16 20:13:13 INFO: Setting up Dataloader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 20:13:20 INFO: Saved segmentation to test_output/segmentation.nii.gz\n",
      "2024-01-16 20:13:20 INFO: Finished inference \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from brainles_aurora.inferer.inferer import AuroraGPUInferer, AuroraInferer\n",
    "from brainles_aurora.inferer.dataclasses import AuroraInfererConfig\n",
    "\n",
    "config = AuroraInfererConfig(\n",
    "    tta=False\n",
    ")  # disable tta for faster inference in this showcase\n",
    "\n",
    "# If you don-t have a GPU that supports CUDA use the CPU version: AuroraInferer(config=config)\n",
    "inferer = AuroraGPUInferer(config=config)\n",
    "\n",
    "inferer.infer(\n",
    "    t1=\"example_data/BraTS-MET-00110-000-t1c.nii.gz\",\n",
    "    segmentation_file=\"test_output/segmentation.nii.gz\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many possibilities for customization:\n",
    "- Any of the following combination of sequences can be supplied: \n",
    "    - T1-CE + T1 + T2 + T2-FLAIR\n",
    "    - T1-CE only\n",
    "    - T1 only\n",
    "    - T2-FLAIR only\n",
    "    - T1-CE + T2-FLAIR\n",
    "    - T1-CE + T1\n",
    "    - T1-CE + T1 + T2-FLAIR\n",
    "- Instead of only saving the final output consisting of one file with 2 labels, additional files with labels for the whole lesion (metastasis + edema) or the metastasis only can also be saved.\n",
    "- Test-time augmentation can be enabled. Segmentation with TTA will take around 10 times longer than without TTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib import single_inference\n",
    "\n",
    "# single_inference(\n",
    "#     t1_file=\"Examples/BraTS-MET-00110-000-t1n.nii.gz\",\n",
    "#     t1c_file=\"Examples/BraTS-MET-00110-000-t1c.nii.gz\",\n",
    "#     t2_file=\"Examples/BraTS-MET-00110-000-t2w.nii.gz\",\n",
    "#     fla_file=\"Examples/BraTS-MET-00110-000-t2f.nii.gz\",\n",
    "#     segmentation_file=\"Examples/your_segmentation_file.nii.gz\",\n",
    "#     whole_network_outputs_file=\"Examples/your_whole_lesion_file.nii.gz\",  # optional: whether to save network outputs for the whole lesion (metastasis + edema)\n",
    "#     metastasis_network_outputs_file=\"Examples/your_metastasis_file.nii.gz\",  # optional: whether to save network outputs for the metastasis\n",
    "#     cuda_devices=\"0\",  # optional: which CUDA devices to use\n",
    "#     tta=True,  # optional: whether to use test time augmentations\n",
    "#     sliding_window_batch_size=1,  # optional: adjust to fit your GPU memory, each step requires an additional 2 GB of VRAM, increasing is not recommended for single interference\n",
    "#     workers=8,  # optional: workers for the data laoder\n",
    "#     threshold=0.5,  # optional: where to threshold the network outputs\n",
    "#     sliding_window_overlap=0.5,  # optional: overlap for the sliding window\n",
    "#     model_selection=\"best\",  # optional: choose best or last checkpoint, best is recommended\n",
    "#     verbosity=True,  # optional: verbosity of the output\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
